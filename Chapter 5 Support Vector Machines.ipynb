{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca32ab2",
   "metadata": {},
   "source": [
    "# chapter5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3906a4",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c39dc",
   "metadata": {},
   "source": [
    "capable of performing linear or nonlinear classification, regression, and even\n",
    "outlier detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd752c48",
   "metadata": {},
   "source": [
    "# Linear SVM Classication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b0fff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The two\n",
    "classes can clearly be separated easily with a straight line (they are linearly separable).\n",
    "\n",
    "the\n",
    "solid line in the plot on the right represents the decision boundary of an SVM classi‐\n",
    "fier; this line not only separates the two classes but also stays as far away from the\n",
    "closest training instances as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16bed50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=inf, kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "X = X[setosa_or_versicolor]\n",
    "y = y[setosa_or_versicolor]\n",
    "\n",
    "# SVM Classifier model\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffdfd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ccc9a36",
   "metadata": {},
   "source": [
    "# Soft Margin Classication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6c099",
   "metadata": {},
   "source": [
    "If we strictly impose that all instances be off the street and on the right side, this is\n",
    "called hard margin classification. There are two main issues with hard margin classifi‐\n",
    "cation. First, it only works if the data is linearly separable, and second it is quite sensi‐\n",
    "tive to outliers.\n",
    "\n",
    "To avoid these issues it is preferable to use a more flexible model. The objective is to\n",
    "find a good balance between keeping the street as large as possible and limiting the\n",
    "margin violations (i.e., instances that end up in the middle of the street or even on the\n",
    "wrong side). This is called so margin classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815f26c",
   "metadata": {},
   "source": [
    "In Scikit-Learn’s SVM classes, you can control this balance using the C hyperparame‐\n",
    "ter: a smaller C value leads to a wider street but more margin violations.\n",
    "\n",
    "If your SVM model is overfitting, you can try regularizing it by\n",
    "reducing C.\n",
    "\n",
    "\n",
    "following Scikit-Learn code loads the iris dataset, scales the features, and then\n",
    "trains a linear SVM model (using the LinearSVC class with C = 1 and the hinge loss\n",
    "function, described shortly) to detect Iris-Virginica flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d32188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0008a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype('float64') # Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0baea7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1,loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "pp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7eefd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd1dcb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.predict([[1.7, 0.4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f73f65",
   "metadata": {},
   "source": [
    "1. The LinearSVC class regularizes the bias term, so you should center\n",
    "the training set first by subtracting its mean. This is automatic if\n",
    "you scale the data using the StandardScaler. \n",
    "2. Moreover, make sure\n",
    "you set the loss hyperparameter to \"hinge\", as it is not the default\n",
    "value. \n",
    "3. Finally, for better performance you should set the dual\n",
    "hyperparameter to False, unless there are more features than\n",
    "training instances (we will discuss duality later in the chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597237",
   "metadata": {},
   "source": [
    "Unlike Logistic Regression classifiers, SVM classifiers do not out‐\n",
    "put probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa059343",
   "metadata": {},
   "source": [
    "Alternatively, you could use the SVC class, using SVC(kernel=\"linear\", C=1), but it\n",
    "is much slower, especially with large training sets, so it is not recommended. Another\n",
    "\n",
    "\n",
    "option is to use the SGDClassifier class, with SGDClassifier(loss=\"hinge\",\n",
    "alpha=1/(m*C)). This applies regular Stochastic Gradient Descent (see Chapter 4) to\n",
    "train a linear SVM classifier. It does not converge as fast as the LinearSVC class, but it\n",
    "can be useful to handle huge datasets that do not fit in memory (out-of-core train‐\n",
    "ing), or to handle online classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "724fe40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SVC(kernel=\"linear\", C=1)\n",
    "s.fit(X,y)\n",
    "s.predict([[1.7, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2218eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc',SVC(kernel=\"linear\", C=1) )\n",
    "])\n",
    "\n",
    "pp.fit(X,y)\n",
    "pp.predict([[1.7, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b53e89ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sg = SGDClassifier(loss=\"hinge\",alpha=1/(150*1))\n",
    "sg.fit(X,y)\n",
    "sg.predict([[1.7, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fd19449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd',SGDClassifier(loss=\"hinge\",alpha=1/(150*1)) )\n",
    "])\n",
    "\n",
    "pp.fit(X,y)\n",
    "pp.predict([[1.7, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649c2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c899af0f",
   "metadata": {},
   "source": [
    "# Nonlinear SVM Classication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc706c",
   "metadata": {},
   "source": [
    "Although linear SVM classifiers are efficient and work surprisingly well in many\n",
    "cases, many datasets are not even close to being linearly separable. One approach to\n",
    "handling nonlinear datasets is to add more features, such as polynomial features in some cases this can result in a linearly separable dataset.\n",
    "\n",
    "\n",
    "To implement this idea using Scikit-Learn, you can create a Pipeline containing a\n",
    "PolynomialFeatures transformer (discussed in “Polynomial Regression” on page\n",
    "130), followed by a StandardScaler and a LinearSVC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a4e3a",
   "metadata": {},
   "source": [
    "Let’s test this on the moons\n",
    "dataset: this is a toy dataset for binary classification in which the data points are sha‐\n",
    "ped as two interleaving half circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34d52318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "343aabea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_svm_clf = Pipeline([\n",
    " (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    " (\"scaler\", StandardScaler()),\n",
    " (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    " ])\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e5f7990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(clf, axes):\n",
    "    x0s = np.linspace(axes[0], axes[1], 100)\n",
    "    x1s = np.linspace(axes[2], axes[3], 100)\n",
    "    x0, x1 = np.meshgrid(x0s, x1s)\n",
    "    X = np.c_[x0.ravel(), x1.ravel()]\n",
    "    y_pred = clf.predict(X).reshape(x0.shape)\n",
    "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
    "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
    "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
    "\n",
    "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00150b",
   "metadata": {},
   "source": [
    "# Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9c27f",
   "metadata": {},
   "source": [
    "1. Adding polynomial features is simple to implement and can work great with all sorts\n",
    "of Machine Learning algorithms (not just SVMs), but at a low polynomial degree it\n",
    "cannot deal with very complex datasets, and with a high polynomial degree it creates\n",
    "a huge number of features, making the model too slow.\n",
    "2. Fortunately, when using SVMs you can apply an almost miraculous mathematical\n",
    "technique called the kernel trick (it is explained in a moment). It makes it possible to\n",
    "get the same result as if you added many polynomial features, even with very high\u0002degree polynomials, without actually having to add them. So there is no combinato‐\n",
    "rial explosion of the number of features since you don’t actually add any features. This\n",
    "trick is implemented by the SVC class. Let’s test it on the moons dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "080e04bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svc', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "pp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    ('svc', SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "pp.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf93b7a",
   "metadata": {},
   "source": [
    "The hyperparameter coef0 controls how much the model is influenced by high\u0002degree polynomials versus low-degree polynomi\n",
    "\n",
    "A common approach to find the right hyperparameter values is to\n",
    "use grid search (see Chapter 2). It is often faster to first do a very\n",
    "coarse grid search, then a finer grid search around the best values\n",
    "found. Having a good sense of what each hyperparameter actually\n",
    "does can also help you search in the right part of the hyperparame‐\n",
    "ter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232c0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "707620cf",
   "metadata": {},
   "source": [
    "SVC()\n",
    "C-Support Vector Classification.\n",
    "\n",
    "The implementation is based on libsvm. The fit time scales at least\n",
    "quadratically with the number of samples and may be impractical\n",
    "beyond tens of thousands of samples. For large datasets\n",
    "consider using :class:`~sklearn.svm.LinearSVC` or\n",
    ":class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
    ":class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
    "\n",
    "The multiclass support is handled according to a one-vs-one scheme.\n",
    "\n",
    "C : float, default=1.0\n",
    "    Regularization parameter. The strength of the regularization is\n",
    "    inversely proportional to C. Must be strictly positive. The penalty\n",
    "    is a squared l2 penalty.\n",
    "\n",
    "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
    "    Specifies the kernel type to be used in the algorithm.\n",
    "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
    "    a callable.\n",
    "    If none is given, 'rbf' will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f414b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b294c9a6",
   "metadata": {},
   "source": [
    "LinearSVC()\n",
    "Linear Support Vector Classification.\n",
    "\n",
    "Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
    "liblinear rather than libsvm, so it has more flexibility in the choice of\n",
    "penalties and loss functions and should scale better to large numbers of\n",
    "samples.\n",
    "\n",
    "This class supports both dense and sparse input and the multiclass support\n",
    "is handled according to a one-vs-the-rest scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee02e7",
   "metadata": {},
   "source": [
    "# Adding Similarity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Another technique to tackle nonlinear problems is to add features computed using a\n",
    "similarity function that measures how much each instance resembles a particular\n",
    "landmark.\n",
    "\n",
    "define the similarity function to be the Gaussian Radial Basis Function (RBF)\n",
    "with γ = 0.3\n",
    "\n",
    "It is a bell-shaped function varying from 0 (very far away from the landmark) to 1 (at\n",
    "the landmark).\n",
    "\n",
    "If your training set is very large, you end up with an\n",
    "equally large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cfd43",
   "metadata": {},
   "source": [
    "#### Gaussian RBF Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca214ee",
   "metadata": {},
   "source": [
    "Just like the polynomial features method, the similarity features method can be useful\n",
    "with any Machine Learning algorithm, but it may be computationally expensive to\n",
    "compute all the additional features, especially on large training sets. However, once\n",
    "again the kernel trick does its SVM magic: it makes it possible to obtain a similar\n",
    "result as if you had added many similarity features, without actually having to add\n",
    "them. Let’s try the Gaussian RBF kernel using the SVC class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c556742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "    ])\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde13f0c",
   "metadata": {},
   "source": [
    " 1. Increasing\n",
    "gamma makes the bell-shape curve narrower (see the left plot of Figure 5-8), and as a\n",
    "result each instance’s range of influence is smaller: the decision boundary ends up\n",
    "being more irregular, wiggling around individual instances. \n",
    "\n",
    "2. a small gamma\n",
    "value makes the bell-shaped curve wider, so instances have a larger range of influ‐\n",
    "ence, and the decision boundary ends up smoother. \n",
    "3. So γ acts like a regularization\n",
    "hyperparameter: \n",
    "4. if your model is overfitting, you should reduce it, and \n",
    "5. if it is under‐\n",
    "fitting, you should increase it (similar to the C hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57972c2b",
   "metadata": {},
   "source": [
    "conclusion\n",
    "\n",
    "1. With so many kernels to choose from, how can you decide which\n",
    "one to use? As a rule of thumb, \n",
    "2. you should always try the linear\n",
    "kernel first (remember that LinearSVC is much faster than SVC(ker\n",
    "nel=\"linear\")), especially if the training set is very large or if it\n",
    "has plenty of features. \n",
    "3. If the training set is not too large, you should\n",
    "try the Gaussian RBF kernel as well; it works well in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b2cc8",
   "metadata": {},
   "source": [
    "# computational comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e6f62",
   "metadata": {},
   "source": [
    "1. The LinearSVC class is based on the liblinear library, which implements an optimized\n",
    "algorithm for linear SVMs.1\n",
    "2. It does not support the kernel trick, but it scales almost linearly with the number of training instances and the number of features: its training\n",
    "time complexity is roughly O(m × n).\n",
    "3. The algorithm takes longer if you require a very high precision. This is controlled by\n",
    "the tolerance hyperparameter ϵ (called tol in Scikit-Learn). In most classification\n",
    "tasks, the default tolerance is fine.\n",
    "\n",
    "\n",
    "1. The SVC class is based on the libsvm library, which implements an algorithm that sup‐\n",
    "ports the kernel trick.2\n",
    " The training time complexity is usually between O(m2\n",
    " × n)\n",
    "and O(m3\n",
    " × n). \n",
    "2. Unfortunately, this means that it gets dreadfully slow when the num‐\n",
    "ber of training instances gets large (e.g., hundreds of thousands of instances). This\n",
    "3. algorithm is perfect for complex but small or medium training sets. \n",
    "4. However, it scales\n",
    "well with the number of features, especially with sparse features (i.e., when each\n",
    "instance has few nonzero features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b447b77",
   "metadata": {},
   "source": [
    "# SVM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23a8d3",
   "metadata": {},
   "source": [
    "1. SVM algorithm is quite versatile: not only does it sup‐\n",
    "port linear and nonlinear classification, but it also supports linear and nonlinear\n",
    "regression. \n",
    "2. The trick is to reverse the objective: instead of trying to fit the largest pos‐\n",
    "sible street between two classes while limiting margin violations, SVM Regression\n",
    "tries to fit as many instances as possible on the street while limiting margin violations\n",
    "(i.e., instances o the street). \n",
    "3. The width of the street is controlled by a hyperparame‐\n",
    "ter ϵ\n",
    "4. Adding more training instances within the margin does not affect the model’s predic‐\n",
    "tions; thus, the model is said to be ϵ-insensitive.\n",
    "\n",
    "\n",
    " Scikit-Learn’s LinearSVR class to perform linear SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18253b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b99f9",
   "metadata": {},
   "source": [
    "1. To tackle nonlinear regression tasks, you can use a kernelized SVM model.\n",
    "2. The following code produces the model represented on the left of Figure 5-11 using\n",
    "Scikit-Learn’s SVR class (which supports the kernel trick). \n",
    "3. The SVR class is the regres‐\n",
    "sion equivalent of the SVC class, and \n",
    "4. the LinearSVR class is the regression equivalent\n",
    "of the LinearSVC class. \n",
    "5. The LinearSVR class scales linearly with the size of the train‐\n",
    "ing set (just like the LinearSVC class), \n",
    "6. while the SVR class gets much too slow when\n",
    "the training set grows large (just like the SVC class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca407c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231c3a5",
   "metadata": {},
   "source": [
    "SVMs can also be used for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapter5\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "capable of performing linear or nonlinear classification, regression, and even\n",
    "outlier detection. \n",
    "\n",
    "# Linear SVM Classication\n",
    "\n",
    "\n",
    "\n",
    "The two\n",
    "classes can clearly be separated easily with a straight line (they are linearly separable).\n",
    "\n",
    "the\n",
    "solid line in the plot on the right represents the decision boundary of an SVM classi‐\n",
    "fier; this line not only separates the two classes but also stays as far away from the\n",
    "closest training instances as possible. \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "setosa_or_versicolor = (y == 0) | (y == 1)\n",
    "X = X[setosa_or_versicolor]\n",
    "y = y[setosa_or_versicolor]\n",
    "\n",
    "# SVM Classifier model\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))\n",
    "svm_clf.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Soft Margin Classication\n",
    "\n",
    "If we strictly impose that all instances be off the street and on the right side, this is\n",
    "called hard margin classification. There are two main issues with hard margin classifi‐\n",
    "cation. First, it only works if the data is linearly separable, and second it is quite sensi‐\n",
    "tive to outliers.\n",
    "\n",
    "To avoid these issues it is preferable to use a more flexible model. The objective is to\n",
    "find a good balance between keeping the street as large as possible and limiting the\n",
    "margin violations (i.e., instances that end up in the middle of the street or even on the\n",
    "wrong side). This is called so margin classification\n",
    "\n",
    "In Scikit-Learn’s SVM classes, you can control this balance using the C hyperparame‐\n",
    "ter: a smaller C value leads to a wider street but more margin violations.\n",
    "\n",
    "If your SVM model is overfitting, you can try regularizing it by\n",
    "reducing C.\n",
    "\n",
    "\n",
    "following Scikit-Learn code loads the iris dataset, scales the features, and then\n",
    "trains a linear SVM model (using the LinearSVC class with C = 1 and the hinge loss\n",
    "function, described shortly) to detect Iris-Virginica flowers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype('float64') # Iris-Virginica\n",
    "\n",
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1,loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "pp.fit(X,y)\n",
    "\n",
    "pp.predict([[5.5, 1.7]])\n",
    "\n",
    "pp.predict([[1.7, 0.4]])\n",
    "\n",
    "1. The LinearSVC class regularizes the bias term, so you should center\n",
    "the training set first by subtracting its mean. This is automatic if\n",
    "you scale the data using the StandardScaler. \n",
    "2. Moreover, make sure\n",
    "you set the loss hyperparameter to \"hinge\", as it is not the default\n",
    "value. \n",
    "3. Finally, for better performance you should set the dual\n",
    "hyperparameter to False, unless there are more features than\n",
    "training instances (we will discuss duality later in the chapter)\n",
    "\n",
    "Unlike Logistic Regression classifiers, SVM classifiers do not out‐\n",
    "put probabilities for each class.\n",
    "\n",
    "Alternatively, you could use the SVC class, using SVC(kernel=\"linear\", C=1), but it\n",
    "is much slower, especially with large training sets, so it is not recommended. Another\n",
    "\n",
    "\n",
    "option is to use the SGDClassifier class, with SGDClassifier(loss=\"hinge\",\n",
    "alpha=1/(m*C)). This applies regular Stochastic Gradient Descent (see Chapter 4) to\n",
    "train a linear SVM classifier. It does not converge as fast as the LinearSVC class, but it\n",
    "can be useful to handle huge datasets that do not fit in memory (out-of-core train‐\n",
    "ing), or to handle online classification tasks\n",
    "\n",
    "s = SVC(kernel=\"linear\", C=1)\n",
    "s.fit(X,y)\n",
    "s.predict([[1.7, 0.4]])\n",
    "\n",
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc',SVC(kernel=\"linear\", C=1) )\n",
    "])\n",
    "\n",
    "pp.fit(X,y)\n",
    "pp.predict([[1.7, 0.4]])\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sg = SGDClassifier(loss=\"hinge\",alpha=1/(150*1))\n",
    "sg.fit(X,y)\n",
    "sg.predict([[1.7, 0.4]])\n",
    "\n",
    "pp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd',SGDClassifier(loss=\"hinge\",alpha=1/(150*1)) )\n",
    "])\n",
    "\n",
    "pp.fit(X,y)\n",
    "pp.predict([[1.7, 0.4]])\n",
    "\n",
    "\n",
    "\n",
    "# Nonlinear SVM Classication\n",
    "\n",
    "\n",
    "Although linear SVM classifiers are efficient and work surprisingly well in many\n",
    "cases, many datasets are not even close to being linearly separable. One approach to\n",
    "handling nonlinear datasets is to add more features, such as polynomial features in some cases this can result in a linearly separable dataset.\n",
    "\n",
    "\n",
    "To implement this idea using Scikit-Learn, you can create a Pipeline containing a\n",
    "PolynomialFeatures transformer (discussed in “Polynomial Regression” on page\n",
    "130), followed by a StandardScaler and a LinearSVC.\n",
    "\n",
    "Let’s test this on the moons\n",
    "dataset: this is a toy dataset for binary classification in which the data points are sha‐\n",
    "ped as two interleaving half circles\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    " (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    " (\"scaler\", StandardScaler()),\n",
    " (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    " ])\n",
    "polynomial_svm_clf.fit(X, y)\n",
    "\n",
    "def plot_predictions(clf, axes):\n",
    "    x0s = np.linspace(axes[0], axes[1], 100)\n",
    "    x1s = np.linspace(axes[2], axes[3], 100)\n",
    "    x0, x1 = np.meshgrid(x0s, x1s)\n",
    "    X = np.c_[x0.ravel(), x1.ravel()]\n",
    "    y_pred = clf.predict(X).reshape(x0.shape)\n",
    "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
    "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
    "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
    "\n",
    "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Polynomial Kernel\n",
    "\n",
    "1. Adding polynomial features is simple to implement and can work great with all sorts\n",
    "of Machine Learning algorithms (not just SVMs), but at a low polynomial degree it\n",
    "cannot deal with very complex datasets, and with a high polynomial degree it creates\n",
    "a huge number of features, making the model too slow.\n",
    "2. Fortunately, when using SVMs you can apply an almost miraculous mathematical\n",
    "technique called the kernel trick (it is explained in a moment). It makes it possible to\n",
    "get the same result as if you added many polynomial features, even with very high\u0002degree polynomials, without actually having to add them. So there is no combinato‐\n",
    "rial explosion of the number of features since you don’t actually add any features. This\n",
    "trick is implemented by the SVC class. Let’s test it on the moons dataset:\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "pp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    ('svc', SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "pp.fit(X,y)\n",
    "\n",
    "The hyperparameter coef0 controls how much the model is influenced by high\u0002degree polynomials versus low-degree polynomi\n",
    "\n",
    "A common approach to find the right hyperparameter values is to\n",
    "use grid search (see Chapter 2). It is often faster to first do a very\n",
    "coarse grid search, then a finer grid search around the best values\n",
    "found. Having a good sense of what each hyperparameter actually\n",
    "does can also help you search in the right part of the hyperparame‐\n",
    "ter space.\n",
    "\n",
    "\n",
    "\n",
    "SVC()\n",
    "C-Support Vector Classification.\n",
    "\n",
    "The implementation is based on libsvm. The fit time scales at least\n",
    "quadratically with the number of samples and may be impractical\n",
    "beyond tens of thousands of samples. For large datasets\n",
    "consider using :class:`~sklearn.svm.LinearSVC` or\n",
    ":class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
    ":class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
    "\n",
    "The multiclass support is handled according to a one-vs-one scheme.\n",
    "\n",
    "C : float, default=1.0\n",
    "    Regularization parameter. The strength of the regularization is\n",
    "    inversely proportional to C. Must be strictly positive. The penalty\n",
    "    is a squared l2 penalty.\n",
    "\n",
    "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
    "    Specifies the kernel type to be used in the algorithm.\n",
    "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
    "    a callable.\n",
    "    If none is given, 'rbf' will be used.\n",
    "\n",
    "\n",
    "\n",
    "LinearSVC()\n",
    "Linear Support Vector Classification.\n",
    "\n",
    "Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
    "liblinear rather than libsvm, so it has more flexibility in the choice of\n",
    "penalties and loss functions and should scale better to large numbers of\n",
    "samples.\n",
    "\n",
    "This class supports both dense and sparse input and the multiclass support\n",
    "is handled according to a one-vs-the-rest scheme.\n",
    "\n",
    "# Adding Similarity Features\n",
    "\n",
    "Another technique to tackle nonlinear problems is to add features computed using a\n",
    "similarity function that measures how much each instance resembles a particular\n",
    "landmark.\n",
    "\n",
    "define the similarity function to be the Gaussian Radial Basis Function (RBF)\n",
    "with γ = 0.3\n",
    "\n",
    "It is a bell-shaped function varying from 0 (very far away from the landmark) to 1 (at\n",
    "the landmark).\n",
    "\n",
    "If your training set is very large, you end up with an\n",
    "equally large number of features.\n",
    "\n",
    "#### Gaussian RBF Kernel\n",
    "\n",
    "\n",
    "Just like the polynomial features method, the similarity features method can be useful\n",
    "with any Machine Learning algorithm, but it may be computationally expensive to\n",
    "compute all the additional features, especially on large training sets. However, once\n",
    "again the kernel trick does its SVM magic: it makes it possible to obtain a similar\n",
    "result as if you had added many similarity features, without actually having to add\n",
    "them. Let’s try the Gaussian RBF kernel using the SVC class:\n",
    "\n",
    "rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "    ])\n",
    "rbf_kernel_svm_clf.fit(X, y)\n",
    "\n",
    " 1. Increasing\n",
    "gamma makes the bell-shape curve narrower (see the left plot of Figure 5-8), and as a\n",
    "result each instance’s range of influence is smaller: the decision boundary ends up\n",
    "being more irregular, wiggling around individual instances. \n",
    "\n",
    "2. a small gamma\n",
    "value makes the bell-shaped curve wider, so instances have a larger range of influ‐\n",
    "ence, and the decision boundary ends up smoother. \n",
    "3. So γ acts like a regularization\n",
    "hyperparameter: \n",
    "4. if your model is overfitting, you should reduce it, and \n",
    "5. if it is under‐\n",
    "fitting, you should increase it (similar to the C hyperparameter)\n",
    "\n",
    "conclusion\n",
    "\n",
    "1. With so many kernels to choose from, how can you decide which\n",
    "one to use? As a rule of thumb, \n",
    "2. you should always try the linear\n",
    "kernel first (remember that LinearSVC is much faster than SVC(ker\n",
    "nel=\"linear\")), especially if the training set is very large or if it\n",
    "has plenty of features. \n",
    "3. If the training set is not too large, you should\n",
    "try the Gaussian RBF kernel as well; it works well in most cases.\n",
    "\n",
    "# computational comparision\n",
    "\n",
    "1. The LinearSVC class is based on the liblinear library, which implements an optimized\n",
    "algorithm for linear SVMs.1\n",
    "2. It does not support the kernel trick, but it scales almost linearly with the number of training instances and the number of features: its training\n",
    "time complexity is roughly O(m × n).\n",
    "3. The algorithm takes longer if you require a very high precision. This is controlled by\n",
    "the tolerance hyperparameter ϵ (called tol in Scikit-Learn). In most classification\n",
    "tasks, the default tolerance is fine.\n",
    "\n",
    "\n",
    "1. The SVC class is based on the libsvm library, which implements an algorithm that sup‐\n",
    "ports the kernel trick.2\n",
    " The training time complexity is usually between O(m2\n",
    " × n)\n",
    "and O(m3\n",
    " × n). \n",
    "2. Unfortunately, this means that it gets dreadfully slow when the num‐\n",
    "ber of training instances gets large (e.g., hundreds of thousands of instances). This\n",
    "3. algorithm is perfect for complex but small or medium training sets. \n",
    "4. However, it scales\n",
    "well with the number of features, especially with sparse features (i.e., when each\n",
    "instance has few nonzero features).\n",
    "\n",
    "# SVM Regression\n",
    "\n",
    "1. SVM algorithm is quite versatile: not only does it sup‐\n",
    "port linear and nonlinear classification, but it also supports linear and nonlinear\n",
    "regression. \n",
    "2. The trick is to reverse the objective: instead of trying to fit the largest pos‐\n",
    "sible street between two classes while limiting margin violations, SVM Regression\n",
    "tries to fit as many instances as possible on the street while limiting margin violations\n",
    "(i.e., instances o the street). \n",
    "3. The width of the street is controlled by a hyperparame‐\n",
    "ter ϵ\n",
    "4. Adding more training instances within the margin does not affect the model’s predic‐\n",
    "tions; thus, the model is said to be ϵ-insensitive.\n",
    "\n",
    "\n",
    " Scikit-Learn’s LinearSVR class to perform linear SVM Regression\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y)\n",
    "\n",
    "\n",
    "1. To tackle nonlinear regression tasks, you can use a kernelized SVM model.\n",
    "2. The following code produces the model represented on the left of Figure 5-11 using\n",
    "Scikit-Learn’s SVR class (which supports the kernel trick). \n",
    "3. The SVR class is the regres‐\n",
    "sion equivalent of the SVC class, and \n",
    "4. the LinearSVR class is the regression equivalent\n",
    "of the LinearSVC class. \n",
    "5. The LinearSVR class scales linearly with the size of the train‐\n",
    "ing set (just like the LinearSVC class), \n",
    "6. while the SVR class gets much too slow when\n",
    "the training set grows large (just like the SVC class).\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)\n",
    "\n",
    "SVMs can also be used for outlier detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
